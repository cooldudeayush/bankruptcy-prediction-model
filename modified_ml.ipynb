{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99f6644d-b9ea-4e32-a322-2ad2c564cb34",
   "metadata": {},
   "source": [
    "<h1>Bankruptcy Prediction Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "078cc0f0-75d8-418f-bfdc-dcbf53d00414",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import arff\n",
    "from glob import glob\n",
    "\n",
    "# Sklearn / Imputation / Scaling / Model\n",
    "from sklearn.experimental import enable_iterative_imputer  # noqa: F401\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix, classification_report\n",
    ")\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed6e835c-4fb4-4a2c-bcde-d0f48deb74c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded datasets for horizons: [1, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "# Load Dataset\n",
    "\n",
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "\n",
    "def load_arff_file(path):\n",
    "    \"\"\"Load a single ARFF file and clean the data.\"\"\"\n",
    "    data, meta = arff.loadarff(path)\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Convert byte columns to numeric if needed\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == object:\n",
    "            df[col] = df[col].apply(lambda x: x.decode() if isinstance(x, bytes) else x)\n",
    "            try:\n",
    "                df[col] = df[col].astype(float)\n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "    # Ensure class column is integer (0/1)\n",
    "    if 'class' in df.columns:\n",
    "        df['class'] = df['class'].astype(int)\n",
    "    else:\n",
    "        raise ValueError(f\"'class' column not found in {path}\")\n",
    "    return df\n",
    "\n",
    "file_names = [\"1year.arff\", \"2year.arff\", \"3year.arff\", \"4year.arff\", \"5year.arff\"]\n",
    "year_datasets = {}\n",
    "\n",
    "for i, fname in enumerate(file_names, start=1):\n",
    "    df = load_arff_file(fname)\n",
    "    df['company_name'] = [f\"Company_{j}\" for j in range(1, len(df)+1)]\n",
    "    year_datasets[i] = df\n",
    "\n",
    "print(\"‚úÖ Loaded datasets for horizons:\", list(year_datasets.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e48f82b-f788-4142-ae55-dad4a4a701a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "üèÅ TRAINING & EVALUATION: 1-Year Horizon\n",
      "==================================================\n",
      "üìä Data Split Summary ‚Üí Train: 4917, Val: 1055, Test: 1055\n",
      "[LightGBM] [Info] Number of positive: 189, number of negative: 4728\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003061 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4623\n",
      "[LightGBM] [Info] Number of data points in the train set: 4917, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038438 -> initscore=-3.219511\n",
      "[LightGBM] [Info] Start training from score -3.219511\n",
      "\n",
      "üìà Validation Metrics (15% data):\n",
      "Accuracy : 0.977\n",
      "Precision: 0.815\n",
      "Recall   : 0.537\n",
      "F1-Score : 0.647\n",
      "AUC-ROC  : 0.875\n",
      "\n",
      "==================================================\n",
      "üèÅ TRAINING & EVALUATION: 2-Year Horizon\n",
      "==================================================\n",
      "üìä Data Split Summary ‚Üí Train: 7120, Val: 1527, Test: 1526\n",
      "[LightGBM] [Info] Number of positive: 280, number of negative: 6840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002670 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 16320\n",
      "[LightGBM] [Info] Number of data points in the train set: 7120, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039326 -> initscore=-3.195753\n",
      "[LightGBM] [Info] Start training from score -3.195753\n",
      "\n",
      "üìà Validation Metrics (15% data):\n",
      "Accuracy : 0.980\n",
      "Precision: 0.917\n",
      "Recall   : 0.550\n",
      "F1-Score : 0.688\n",
      "AUC-ROC  : 0.954\n",
      "\n",
      "==================================================\n",
      "üèÅ TRAINING & EVALUATION: 3-Year Horizon\n",
      "==================================================\n",
      "üìä Data Split Summary ‚Üí Train: 7351, Val: 1576, Test: 1576\n",
      "[LightGBM] [Info] Number of positive: 347, number of negative: 7004\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003050 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 16320\n",
      "[LightGBM] [Info] Number of data points in the train set: 7351, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.047204 -> initscore=-3.004912\n",
      "[LightGBM] [Info] Start training from score -3.004912\n",
      "\n",
      "üìà Validation Metrics (15% data):\n",
      "Accuracy : 0.973\n",
      "Precision: 0.782\n",
      "Recall   : 0.581\n",
      "F1-Score : 0.667\n",
      "AUC-ROC  : 0.948\n",
      "\n",
      "==================================================\n",
      "üèÅ TRAINING & EVALUATION: 4-Year Horizon\n",
      "==================================================\n",
      "üìä Data Split Summary ‚Üí Train: 6853, Val: 1470, Test: 1469\n",
      "[LightGBM] [Info] Number of positive: 361, number of negative: 6492\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002678 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 16320\n",
      "[LightGBM] [Info] Number of data points in the train set: 6853, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.052678 -> initscore=-2.889448\n",
      "[LightGBM] [Info] Start training from score -2.889448\n",
      "\n",
      "üìà Validation Metrics (15% data):\n",
      "Accuracy : 0.967\n",
      "Precision: 0.792\n",
      "Recall   : 0.494\n",
      "F1-Score : 0.608\n",
      "AUC-ROC  : 0.944\n",
      "\n",
      "==================================================\n",
      "üèÅ TRAINING & EVALUATION: 5-Year Horizon\n",
      "==================================================\n",
      "üìä Data Split Summary ‚Üí Train: 4136, Val: 887, Test: 887\n",
      "[LightGBM] [Info] Number of positive: 287, number of negative: 3849\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003052 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 16320\n",
      "[LightGBM] [Info] Number of data points in the train set: 4136, number of used features: 64\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.069391 -> initscore=-2.596086\n",
      "[LightGBM] [Info] Start training from score -2.596086\n",
      "\n",
      "üìà Validation Metrics (15% data):\n",
      "Accuracy : 0.957\n",
      "Precision: 0.756\n",
      "Recall   : 0.557\n",
      "F1-Score : 0.642\n",
      "AUC-ROC  : 0.951\n"
     ]
    }
   ],
   "source": [
    "#TRAIN + VALIDATE + TEST PIPELINE\n",
    "# ================================\n",
    "\n",
    "models = {}\n",
    "evals = {}\n",
    "\n",
    "for horizon, df in year_datasets.items():\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"üèÅ TRAINING & EVALUATION: {horizon}-Year Horizon\")\n",
    "    print(f\"{'='*50}\")\n",
    "\n",
    "    # -------------------------------\n",
    "    # STEP 1: Prepare data\n",
    "    # -------------------------------\n",
    "    X = df.drop(columns=['class', 'company_name'])\n",
    "    y = df['class'].astype(int)\n",
    "\n",
    "    # 70-15-15 split (stratified)\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "        X, y, test_size=0.15, random_state=42, stratify=y\n",
    "    )\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train_val, y_train_val, test_size=0.1765,  # 0.1765 of 85% ‚âà 15% of total\n",
    "        random_state=42, stratify=y_train_val\n",
    "    )\n",
    "\n",
    "    print(f\"üìä Data Split Summary ‚Üí Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}\")\n",
    "\n",
    "    # -------------------------------\n",
    "    # STEP 2: Handle class imbalance\n",
    "    # -------------------------------\n",
    "    pos_count = int(y_train.sum())\n",
    "    neg_count = int(len(y_train) - pos_count)\n",
    "    pos_weight = (neg_count / pos_count) if pos_count > 0 else 1.0\n",
    "\n",
    "    # -------------------------------\n",
    "    # STEP 3: Build model pipeline\n",
    "    # -------------------------------\n",
    "    pipe = Pipeline([\n",
    "        (\"imputer\", IterativeImputer(random_state=42)),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", LGBMClassifier(\n",
    "            n_estimators=500,\n",
    "            learning_rate=0.05,\n",
    "            max_depth=-1,\n",
    "            scale_pos_weight=pos_weight,\n",
    "            objective=\"binary\",\n",
    "            random_state=42\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    # -------------------------------\n",
    "    # STEP 4: Train on TRAIN set\n",
    "    # -------------------------------\n",
    "    pipe.fit(X_train, y_train)\n",
    "    models[horizon] = pipe\n",
    "\n",
    "    # -------------------------------\n",
    "    # STEP 5: Validate on VALIDATION set\n",
    "    # -------------------------------\n",
    "    val_pred = pipe.predict(X_val)\n",
    "    val_proba = pipe.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    val_acc = accuracy_score(y_val, val_pred)\n",
    "    val_prec = precision_score(y_val, val_pred, zero_division=0)\n",
    "    val_rec = recall_score(y_val, val_pred, zero_division=0)\n",
    "    val_f1 = f1_score(y_val, val_pred, zero_division=0)\n",
    "    val_auc = roc_auc_score(y_val, val_proba)\n",
    "\n",
    "    print(f\"\\nüìà Validation Metrics (15% data):\")\n",
    "    print(f\"Accuracy : {val_acc:.3f}\")\n",
    "    print(f\"Precision: {val_prec:.3f}\")\n",
    "    print(f\"Recall   : {val_rec:.3f}\")\n",
    "    print(f\"F1-Score : {val_f1:.3f}\")\n",
    "    print(f\"AUC-ROC  : {val_auc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "561a73ca-747e-4640-892f-cd1553142959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Final TEST Metrics (15% completely unseen data)\n",
      "----------------------------------\n",
      "Accuracy : 0.963\n",
      "Precision: 0.822\n",
      "Recall   : 0.597\n",
      "F1-Score : 0.692\n",
      "AUC-ROC  : 0.969\n",
      "Confusion Matrix (rows=True, cols=Pred):\n",
      "[[817   8]\n",
      " [ 25  37]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.970     0.990     0.980       825\n",
      "           1      0.822     0.597     0.692        62\n",
      "\n",
      "    accuracy                          0.963       887\n",
      "   macro avg      0.896     0.794     0.836       887\n",
      "weighted avg      0.960     0.963     0.960       887\n",
      "\n",
      "\n",
      "üèÅ All models trained, validated, and evaluated successfully!\n",
      "\n",
      "================= PERFORMANCE SUMMARY =================\n",
      "   val_acc  val_f1  val_auc  test_acc  test_f1  test_auc\n",
      "5    0.957   0.642    0.951     0.963    0.692     0.969\n",
      "========================================================\n"
     ]
    }
   ],
   "source": [
    "# STEP 6: Final evaluation on TEST set\n",
    "\n",
    "y_pred = pipe.predict(X_test)\n",
    "try:\n",
    "    y_proba = pipe.predict_proba(X_test)[:, 1]\n",
    "except Exception:\n",
    "    y_proba = y_pred.astype(float)\n",
    "\n",
    "# --- Safe metric helper ---\n",
    "def safe_metric(fn, *args, **kwargs):\n",
    "    try:\n",
    "        return fn(*args, **kwargs)\n",
    "    except Exception:\n",
    "            return np.nan\n",
    "\n",
    "# --- Compute metrics ---\n",
    "acc = safe_metric(accuracy_score, y_test, y_pred)\n",
    "prec = safe_metric(precision_score, y_test, y_pred, zero_division=0)\n",
    "rec = safe_metric(recall_score, y_test, y_pred, zero_division=0)\n",
    "f1 = safe_metric(f1_score, y_test, y_pred, zero_division=0)\n",
    "auc = safe_metric(roc_auc_score, y_test, y_proba) if len(np.unique(y_test)) > 1 else np.nan\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# STEP 7: Print results cleanly\n",
    "\n",
    "print(f\"\\n Final TEST Metrics (15% completely unseen data)\")\n",
    "print(\"-\" * 34)\n",
    "print(f\"Accuracy : {acc:.3f}\" if not np.isnan(acc) else \"Accuracy : N/A\")\n",
    "print(f\"Precision: {prec:.3f}\" if not np.isnan(prec) else \"Precision: N/A\")\n",
    "print(f\"Recall   : {rec:.3f}\" if not np.isnan(rec) else \"Recall   : N/A\")\n",
    "print(f\"F1-Score : {f1:.3f}\" if not np.isnan(f1) else \"F1-Score : N/A\")\n",
    "print(f\"AUC-ROC  : {auc:.3f}\" if not np.isnan(auc) else \"AUC-ROC  : N/A\")\n",
    "print(\"Confusion Matrix (rows=True, cols=Pred):\")\n",
    "print(cm)\n",
    "print(\"\\nClassification Report:\")\n",
    "try:\n",
    "    print(classification_report(y_test, y_pred, digits=3, zero_division=0))\n",
    "except Exception:\n",
    "    print(\"N/A (single-class y_test)\")\n",
    "\n",
    "# -------------------------------\n",
    "# STEP 8: Save metrics summary\n",
    "# -------------------------------\n",
    "evals[horizon] = {\n",
    "    \"val_acc\": val_acc,\n",
    "    \"val_f1\": val_f1,\n",
    "    \"val_auc\": val_auc,\n",
    "    \"test_acc\": acc,\n",
    "    \"test_prec\": prec,\n",
    "    \"test_rec\": rec,\n",
    "    \"test_f1\": f1,\n",
    "    \"test_auc\": auc,\n",
    "    \"test_cm\": cm\n",
    "    }\n",
    "\n",
    "# -------------------------------\n",
    "#  All models complete\n",
    "\n",
    "print(\"\\nüèÅ All models trained, validated, and evaluated successfully!\")\n",
    "\n",
    "# ================================\n",
    "#  OPTIONAL SUMMARY TABLE\n",
    "# ================================\n",
    "summary = pd.DataFrame.from_dict(evals, orient=\"index\")[[\n",
    "    \"val_acc\", \"val_f1\", \"val_auc\",\n",
    "    \"test_acc\", \"test_f1\", \"test_auc\"\n",
    "]]\n",
    "print(\"\\n================= PERFORMANCE SUMMARY =================\")\n",
    "print(summary.round(3).to_string())\n",
    "print(\"========================================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a31ac9d-de67-411f-9af6-ccbb418dcbc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter company name (e.g. Company_25) or 'exit' to quit:  Company_10009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ö†Ô∏è Company_10009 is predicted to go BANKRUPT within 2 year(s).\n",
      "   (Model confidence: 1.00)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter company name (e.g. Company_25) or 'exit' to quit:  Company_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Company_1 is predicted to REMAIN STABLE across all 1‚Äì5 year horizons.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter company name (e.g. Company_25) or 'exit' to quit:  exit\n"
     ]
    }
   ],
   "source": [
    "#one line summary\n",
    "while True:\n",
    "    company_input = input(\"\\nEnter company name (e.g. Company_25) or 'exit' to quit: \")\n",
    "    if company_input.lower() == 'exit':\n",
    "        break\n",
    "\n",
    "    bankruptcy_year = None  # to store first predicted bankruptcy\n",
    "    bankruptcy_proba = None\n",
    "\n",
    "    for horizon, df in year_datasets.items():\n",
    "        row = df[df['company_name'] == company_input]\n",
    "        if row.empty:\n",
    "            continue\n",
    "\n",
    "        X_row = row.drop(columns=['class', 'company_name'])\n",
    "        pred = models[horizon].predict(X_row)[0]\n",
    "        proba = models[horizon].predict_proba(X_row)[0][1]\n",
    "\n",
    "        if pred == 1:  # predicted bankrupt\n",
    "            bankruptcy_year = horizon\n",
    "            bankruptcy_proba = proba\n",
    "            break  # stop at the earliest year of predicted bankruptcy\n",
    "\n",
    "    if bankruptcy_year is not None:\n",
    "        print(f\"\\n‚ö†Ô∏è {company_input} is predicted to go BANKRUPT within {bankruptcy_year} year(s).\")\n",
    "        print(f\"   (Model confidence: {bankruptcy_proba:.2f})\")\n",
    "    else:\n",
    "        print(f\"\\n‚úÖ {company_input} is predicted to REMAIN STABLE across all 1‚Äì5 year horizons.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
